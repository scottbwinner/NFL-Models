{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8eebc9",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "1. How do you have statistics evaluating players to predict how good they will do that are different based on position?\n",
    "    - Solution A: Evaluate positions separately with ML Models, and have the projected points for each player be passed into the draft bot \n",
    "    - Solution B: Include player statistics with draft data, and have reinforcement use those to choose who to draft, instead of having a ppg number. \n",
    "                  This solution does have issues, as different positions will have different statistics, as will rookies.\n",
    "    - Solution C: Give the reinforcement learning agent the ML predicted ppg as well as player statistics. The RL agent can learn how much trust to place in the projection\n",
    "    - Solution D: Dynamic Season Simulation: Instead of giving just a single projected PPG, simulate season outcomes stochastically and return mean_ppg, std_ppg, ceiling, floor, boom_probability.\n",
    "                  Agent can learn to balance risk/reward based on draft context\n",
    "    - Solution E: Latent Player Embeddings: Train an unsupervised embedding model (e.g. autoencoder) over raw player stats to create compact player vectors. Can be helpful because we have many statistics.\n",
    "    - Solution F: Deep learning with MLP, a Recurrent Model (LSTM/GRU), or a Transformer\n",
    "\n",
    "    - Problem 1b: In solutions where we pass the data directly to reinforcement learning, statistics will not be common amongst different positions.\n",
    "        - Solution A: Make each row have all possible statistics and fill irrelevant datapoints with 0, null, or -1\n",
    "        - Solution B: Build separate feature encoders (small neural nets) for each position type (QB, RB, WR, TE), and pass the output of these encoders to a shared draft policy network. Pretty much making vectors separately and then pass them to one\n",
    "                      decision-making policy?\n",
    "        - Solution C: Instead of having separate encoders for each position like Solution B, you have one position aware encoder.\n",
    "        - Solution D: Positional Streams (Transformer-Style): Model each position group as a separate input stream - like in multimodal learning - and aggregate the ouptuts across all positions when making the decision. (Don't get this)\n",
    "\n",
    "2. How will we deal with Rookies?\n",
    "    - Solution A: Evaluate rookies in a separate database, and base projections over college statistics, draft capital, and other nfl team statistics\n",
    "3. How do we factor in bench? How do we make it so they aren't just going to want to pick QB's for bench spots?\n",
    "    - Solution A: Make position limits for bench\n",
    "    - Solution B: Normalize the ppg for bench players so the ppg factored in will be in relation to position average\n",
    "4. How do we execute the draft? We want the Agent to only be one spot, so we need a bot to perform the draft for all other positions.\n",
    "    - Solution A: Only use ADP and position needs for draft choices to non-agent positions. Need to have a random-esque parameter to determine how unpredictably \n",
    "                  the non-agent positions can draft, they can't always choose highest ADP player, we want some variation. Going to just need to play around with that \n",
    "                  random parameter, would be nice if it could get more and more loose the later the draft goes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Ideas**\n",
    "- Would be cool to have a risk setting to prioritize high risk high reward players or to play things safer, using standard deviation\n",
    "- Add volatility to statistics, the standard deviation of weekly points to show how reliable a player is.\n",
    "- Deep Learning Ideas\n",
    "    - Use a deep policy network (MLP or Transformer) to take draft actions. Represent the player pool using deep encoders or learned embeddings. Encode your current roster as a deep vector and feed it into the policy. Use PPO or SAC for training\n",
    "    - Draft Pool Representation with Transformers or Attention\n",
    "\n",
    "**Problems**\n",
    "\n",
    "\n",
    "\n",
    "### Data Model\n",
    "##### player_draft_data\n",
    "- player_name\n",
    "- position\n",
    "- team_name\n",
    "- season\n",
    "- adp\n",
    "- fantasy_ppg\n",
    "##### qb_evaluation_data\n",
    "- player_name\n",
    "- position\n",
    "- team_name\n",
    "- season\n",
    "- ... evaluation stats ...\n",
    "- Result: projected PPG\n",
    "##### rb_evaluation_data\n",
    "- player_name\n",
    "- position\n",
    "- team_name\n",
    "- season\n",
    "- ... evaluation stats ...\n",
    "- Result: projected PPG\n",
    "##### wr_evaluation_data\n",
    "- player_name\n",
    "- position\n",
    "- team_name\n",
    "- season\n",
    "- ... evaluation stats ...\n",
    "- Result: projected PPG\n",
    "##### te_evaluation_data\n",
    "- player_name\n",
    "- position\n",
    "- team_name\n",
    "- season\n",
    "- ... evaluation stats ...\n",
    "- Result: projected PPG\n",
    "\n",
    "\n",
    "### Draft Set-Up\n",
    "- Parameters:\n",
    "    - starting_qb_num\n",
    "    - starting_rb_num\n",
    "    - starting_wr_num\n",
    "    - starting_flex_num\n",
    "    - starting_te_num\n",
    "    - bench_num\n",
    "    - team_count\n",
    "    - draft_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd45c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
